{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJjspWqLmpub"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "from torch import nn, autograd, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils import data\n",
    "from torchvision import transforms, utils\n",
    "from tqdm import tqdm\n",
    "from dataset.celebahq_img import CelebAHQ\n",
    "\n",
    "\n",
    "from model.stylegan2_pytorch.distributed import (\n",
    "    get_rank,\n",
    "    synchronize,\n",
    "    reduce_loss_dict,\n",
    "    reduce_sum,\n",
    "    get_world_size,\n",
    ")\n",
    "from model.stylegan2_pytorch.op import conv2d_gradfix\n",
    "from model.stylegan2_pytorch.non_leaking import augment, AdaptiveAugment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f--oU9dam1LO"
   },
   "outputs": [],
   "source": [
    "def data_sampler(dataset, shuffle, distributed):\n",
    "    if distributed:\n",
    "        return data.distributed.DistributedSampler(dataset, shuffle=shuffle)\n",
    "\n",
    "    if shuffle:\n",
    "        return data.RandomSampler(dataset)\n",
    "\n",
    "    else:\n",
    "        return data.SequentialSampler(dataset)\n",
    "\n",
    "\n",
    "def requires_grad(model, flag=True):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = flag\n",
    "\n",
    "\n",
    "def accumulate(model1, model2, decay=0.999):\n",
    "    par1 = dict(model1.named_parameters())\n",
    "    par2 = dict(model2.named_parameters())\n",
    "\n",
    "    for k in par1.keys():\n",
    "        par1[k].data.mul_(decay).add_(par2[k].data, alpha=1 - decay)\n",
    "\n",
    "\n",
    "def sample_data(loader):\n",
    "    while True:\n",
    "        for batch in loader:\n",
    "            yield batch\n",
    "\n",
    "\n",
    "def d_logistic_loss(real_pred, fake_pred):\n",
    "    real_loss = F.softplus(-real_pred)\n",
    "    fake_loss = F.softplus(fake_pred)\n",
    "\n",
    "    return real_loss.mean() + fake_loss.mean()\n",
    "\n",
    "\n",
    "def d_r1_loss(real_pred, real_img):\n",
    "    with conv2d_gradfix.no_weight_gradients():\n",
    "        (grad_real,) = autograd.grad(\n",
    "            outputs=real_pred.sum(), inputs=real_img, create_graph=True\n",
    "        )\n",
    "    grad_penalty = grad_real.pow(2).reshape(grad_real.shape[0], -1).sum(1).mean()\n",
    "\n",
    "    return grad_penalty\n",
    "\n",
    "\n",
    "def g_nonsaturating_loss(fake_pred):\n",
    "    loss = F.softplus(-fake_pred).mean()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def g_path_regularize(fake_img, latents, mean_path_length, decay=0.01):\n",
    "    noise = torch.randn_like(fake_img) / math.sqrt(\n",
    "        fake_img.shape[2] * fake_img.shape[3]\n",
    "    )\n",
    "    (grad,) = autograd.grad(\n",
    "        outputs=(fake_img * noise).sum(), inputs=latents, create_graph=True\n",
    "    )\n",
    "    path_lengths = torch.sqrt(grad.pow(2).sum(2).mean(1))\n",
    "\n",
    "    path_mean = mean_path_length + decay * (path_lengths.mean() - mean_path_length)\n",
    "\n",
    "    path_penalty = (path_lengths - path_mean).pow(2).mean()\n",
    "\n",
    "    return path_penalty, path_mean.detach(), path_lengths\n",
    "\n",
    "\n",
    "def make_noise(batch, latent_dim, n_noise, device):\n",
    "    if n_noise == 1:\n",
    "        return torch.randn(batch, latent_dim, device=device)\n",
    "\n",
    "    noises = torch.randn(n_noise, batch, latent_dim, device=device).unbind(0)\n",
    "\n",
    "    return noises\n",
    "\n",
    "\n",
    "def mixing_noise(batch, latent_dim, prob, device):\n",
    "    if prob > 0 and random.random() < prob:\n",
    "        return make_noise(batch, latent_dim, 2, device)\n",
    "\n",
    "    else:\n",
    "        return [make_noise(batch, latent_dim, 1, device)]\n",
    "\n",
    "\n",
    "def set_grad_none(model, targets):\n",
    "    for n, p in model.named_parameters():\n",
    "        if n in targets:\n",
    "            p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JPrEo8PNm8nB"
   },
   "outputs": [],
   "source": [
    "def train(args, loader, generator, discriminator, g_optim, d_optim, g_ema, device):\n",
    "    loader = sample_data(loader)\n",
    "\n",
    "    pbar = range(args.iter)\n",
    "\n",
    "    if get_rank() == 0:\n",
    "        pbar = tqdm(pbar, initial=args.start_iter, dynamic_ncols=True, smoothing=0.01)\n",
    "\n",
    "    mean_path_length = 0\n",
    "\n",
    "    d_loss_val = 0\n",
    "    r1_loss = torch.tensor(0.0, device=device)\n",
    "    g_loss_val = 0\n",
    "    path_loss = torch.tensor(0.0, device=device)\n",
    "    path_lengths = torch.tensor(0.0, device=device)\n",
    "    mean_path_length_avg = 0\n",
    "    loss_dict = {}\n",
    "\n",
    "    if args.distributed:\n",
    "        g_module = generator.module\n",
    "        d_module = discriminator.module\n",
    "\n",
    "    else:\n",
    "        g_module = generator\n",
    "        d_module = discriminator\n",
    "\n",
    "    accum = 0.5 ** (32 / (10 * 1000))\n",
    "    ada_aug_p = args.augment_p if args.augment_p > 0 else 0.0\n",
    "\n",
    "    if args.augment and args.augment_p == 0:\n",
    "        ada_augment = AdaptiveAugment(args.ada_target, args.ada_length, 8, device)\n",
    "\n",
    "    sample_z = torch.randn(args.n_sample, args.latent, device=device)\n",
    "\n",
    "    for idx in pbar:\n",
    "        i = idx + args.start_iter\n",
    "\n",
    "        if i > args.iter:\n",
    "            print(\"Done!\")\n",
    "\n",
    "            break\n",
    "\n",
    "        real_img = next(loader)\n",
    "        real_img = real_img.to(device)\n",
    "\n",
    "        requires_grad(generator, False)\n",
    "        requires_grad(discriminator, True)\n",
    "\n",
    "        noise = mixing_noise(args.batch, args.latent, args.mixing, device)\n",
    "        fake_img, _ = generator(noise)\n",
    "\n",
    "        if args.augment:\n",
    "            real_img_aug, _ = augment(real_img, ada_aug_p)\n",
    "            fake_img, _ = augment(fake_img, ada_aug_p)\n",
    "\n",
    "        else:\n",
    "            real_img_aug = real_img\n",
    "\n",
    "        fake_pred = discriminator(fake_img)\n",
    "        real_pred = discriminator(real_img_aug)\n",
    "        d_loss = d_logistic_loss(real_pred, fake_pred)\n",
    "\n",
    "        loss_dict[\"d\"] = d_loss\n",
    "        loss_dict[\"real_score\"] = real_pred.mean()\n",
    "        loss_dict[\"fake_score\"] = fake_pred.mean()\n",
    "\n",
    "        discriminator.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optim.step()\n",
    "\n",
    "        if args.augment and args.augment_p == 0:\n",
    "            ada_aug_p = ada_augment.tune(real_pred)\n",
    "\n",
    "        d_regularize = i % args.d_reg_every == 0\n",
    "\n",
    "        if d_regularize:\n",
    "            real_img.requires_grad = True\n",
    "\n",
    "            if args.augment:\n",
    "                real_img_aug, _ = augment(real_img, ada_aug_p)\n",
    "\n",
    "            else:\n",
    "                real_img_aug = real_img\n",
    "\n",
    "            real_pred = discriminator(real_img_aug)\n",
    "            r1_loss = d_r1_loss(real_pred, real_img)\n",
    "\n",
    "            discriminator.zero_grad()\n",
    "            (args.r1 / 2 * r1_loss * args.d_reg_every + 0 * real_pred[0]).backward()\n",
    "\n",
    "            d_optim.step()\n",
    "\n",
    "        loss_dict[\"r1\"] = r1_loss\n",
    "\n",
    "        requires_grad(generator, True)\n",
    "        requires_grad(discriminator, False)\n",
    "\n",
    "        noise = mixing_noise(args.batch, args.latent, args.mixing, device)\n",
    "        fake_img, _ = generator(noise)\n",
    "\n",
    "        if args.augment:\n",
    "            fake_img, _ = augment(fake_img, ada_aug_p)\n",
    "\n",
    "        fake_pred = discriminator(fake_img)\n",
    "        g_loss = g_nonsaturating_loss(fake_pred)\n",
    "\n",
    "        loss_dict[\"g\"] = g_loss\n",
    "\n",
    "        generator.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optim.step()\n",
    "\n",
    "        g_regularize = i % args.g_reg_every == 0\n",
    "\n",
    "        if g_regularize:\n",
    "            path_batch_size = max(1, args.batch // args.path_batch_shrink)\n",
    "            noise = mixing_noise(path_batch_size, args.latent, args.mixing, device)\n",
    "            fake_img, latents = generator(noise, return_latents=True)\n",
    "\n",
    "            path_loss, mean_path_length, path_lengths = g_path_regularize(\n",
    "                fake_img, latents, mean_path_length\n",
    "            )\n",
    "\n",
    "            generator.zero_grad()\n",
    "            weighted_path_loss = args.path_regularize * args.g_reg_every * path_loss\n",
    "\n",
    "            if args.path_batch_shrink:\n",
    "                weighted_path_loss += 0 * fake_img[0, 0, 0, 0]\n",
    "\n",
    "            weighted_path_loss.backward()\n",
    "\n",
    "            g_optim.step()\n",
    "\n",
    "            mean_path_length_avg = (\n",
    "                reduce_sum(mean_path_length).item() / get_world_size()\n",
    "            )\n",
    "\n",
    "        loss_dict[\"path\"] = path_loss\n",
    "        loss_dict[\"path_length\"] = path_lengths.mean()\n",
    "\n",
    "        accumulate(g_ema, g_module, accum)\n",
    "\n",
    "        loss_reduced = reduce_loss_dict(loss_dict)\n",
    "\n",
    "        d_loss_val = loss_reduced[\"d\"].mean().item()\n",
    "        g_loss_val = loss_reduced[\"g\"].mean().item()\n",
    "        r1_val = loss_reduced[\"r1\"].mean().item()\n",
    "        path_loss_val = loss_reduced[\"path\"].mean().item()\n",
    "\n",
    "        if get_rank() == 0:\n",
    "            pbar.set_description(\n",
    "                (\n",
    "                    f\"d: {d_loss_val:.4f}; g: {g_loss_val:.4f}; r1: {r1_val:.4f}; \"\n",
    "                    f\"path: {path_loss_val:.4f}; mean path: {mean_path_length_avg:.4f}; \"\n",
    "                    f\"augment: {ada_aug_p:.4f}\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                with torch.no_grad():\n",
    "                    g_ema.eval()\n",
    "                    sample, _ = g_ema([sample_z])\n",
    "                    utils.save_image(\n",
    "                        sample,\n",
    "                        f\"{args.vis_dir}/{str(i).zfill(6)}.jpg\",\n",
    "                        nrow=int(args.n_sample**0.5),\n",
    "                        normalize=True,\n",
    "                        value_range=(-1, 1),\n",
    "                    )\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"g\": g_module.state_dict(),\n",
    "                        \"d\": d_module.state_dict(),\n",
    "                        \"g_ema\": g_ema.state_dict(),\n",
    "                        \"g_optim\": g_optim.state_dict(),\n",
    "                        \"d_optim\": d_optim.state_dict(),\n",
    "                        \"args\": args,\n",
    "                        \"ada_aug_p\": ada_aug_p,\n",
    "                        \"step\": i,\n",
    "                    },\n",
    "                    f\"{args.ckpt_dir}/last.pt\",\n",
    "                )\n",
    "\n",
    "            if i % 50000 == 0:\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"g\": g_module.state_dict(),\n",
    "                        \"d\": d_module.state_dict(),\n",
    "                        \"g_ema\": g_ema.state_dict(),\n",
    "                        \"g_optim\": g_optim.state_dict(),\n",
    "                        \"d_optim\": d_optim.state_dict(),\n",
    "                        \"args\": args,\n",
    "                        \"ada_aug_p\": ada_aug_p,\n",
    "                        \"step\": i,\n",
    "                    },\n",
    "                    f\"{args.ckpt_dir}/{str(i).zfill(6)}.pt\",\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1674075015968,
     "user": {
      "displayName": "Zain Ayaz",
      "userId": "00806274398273992607"
     },
     "user_tz": -300
    },
    "id": "tvwc6TkEpPY7"
   },
   "outputs": [],
   "source": [
    "class Args:\n",
    "    arch = 'stylegan2'\n",
    "    iter = 800000\n",
    "    batch = 1\n",
    "    lr = 0.002\n",
    "    n_sample = 64\n",
    "    size = 64\n",
    "    r1 = 10\n",
    "    path_regularize = 2\n",
    "    path_batch_shrink = 2\n",
    "    d_reg_every = 16\n",
    "    g_reg_every = 4\n",
    "    mixing = 0.9\n",
    "    ckpt = None\n",
    "    channel_multiplier = 2\n",
    "    local_rank = 0\n",
    "    augment = False\n",
    "    augment_p = 0\n",
    "    ada_target = 0.6\n",
    "    ada_length = 500 * 1000\n",
    "    ada_every = 256\n",
    "    num_workers = 4\n",
    "    latent = 512\n",
    "    n_mlp = 8\n",
    "    start_iter = 0\n",
    "    dataset = 'celebahq'\n",
    "    nframes = 32\n",
    "    split = 'train'\n",
    "    device = \"cuda\"\n",
    "    name = None\n",
    "    vis_dir = None\n",
    "    ckpt_dir = None\n",
    "    distributed = None\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PGm8mLr7m_EE"
   },
   "outputs": [],
   "source": [
    "default_name = f\"stylegan2_{args.dataset}_size_{args.size}_split_{args.split}\"\n",
    "\n",
    "if args.name is None:\n",
    "    args.name = default_name\n",
    "else:\n",
    "    args.name = f\"{default_name}_{args.name}\"\n",
    "\n",
    "args.vis_dir = f\"exp/vis/{args.name}\"\n",
    "args.ckpt_dir = f\"exp/ckpt/{args.name}\"\n",
    "\n",
    "if get_rank() == 0:\n",
    "    if not os.path.isdir(args.vis_dir):\n",
    "        os.makedirs(args.vis_dir)\n",
    "    if not os.path.isdir(args.ckpt_dir):\n",
    "        os.makedirs(args.ckpt_dir)\n",
    "\n",
    "n_gpu = int(os.environ[\"WORLD_SIZE\"]) if \"WORLD_SIZE\" in os.environ else 1\n",
    "args.distributed = n_gpu > 1\n",
    "\n",
    "if args.distributed:\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    torch.distributed.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "    synchronize()\n",
    "\n",
    "\n",
    "if args.arch == \"stylegan2\":\n",
    "    from model.stylegan2_pytorch.model import Generator, Discriminator\n",
    "\n",
    "\n",
    "generator = Generator(\n",
    "    args.size, args.latent, args.n_mlp, channel_multiplier=args.channel_multiplier\n",
    ").to(args.device)\n",
    "\n",
    "discriminator = Discriminator(\n",
    "    args.size, channel_multiplier=args.channel_multiplier\n",
    ").to(args.device)\n",
    "\n",
    "g_ema = Generator(\n",
    "    args.size, args.latent, args.n_mlp, channel_multiplier=args.channel_multiplier\n",
    ").to(args.device)\n",
    "\n",
    "g_ema.eval()\n",
    "accumulate(g_ema, generator, 0)\n",
    "\n",
    "g_reg_ratio = args.g_reg_every / (args.g_reg_every + 1)\n",
    "d_reg_ratio = args.d_reg_every / (args.d_reg_every + 1)\n",
    "\n",
    "g_optim = optim.Adam(\n",
    "    generator.parameters(),\n",
    "    lr=args.lr * g_reg_ratio,\n",
    "    betas=(0**g_reg_ratio, 0.99**g_reg_ratio),\n",
    ")\n",
    "\n",
    "d_optim = optim.Adam(\n",
    "    discriminator.parameters(),\n",
    "    lr=args.lr * d_reg_ratio,\n",
    "    betas=(0**d_reg_ratio, 0.99**d_reg_ratio),\n",
    ")\n",
    "\n",
    "if args.ckpt is not None:\n",
    "    print(\"load model:\", args.ckpt)\n",
    "\n",
    "    ckpt = torch.load(args.ckpt, map_location=lambda storage, loc: storage)\n",
    "\n",
    "    try:\n",
    "        ckpt_name = os.path.basename(args.ckpt)\n",
    "        args.start_iter = int(os.path.splitext(ckpt_name)[0])\n",
    "\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    generator.load_state_dict(ckpt[\"g\"])\n",
    "    discriminator.load_state_dict(ckpt[\"d\"])\n",
    "    g_ema.load_state_dict(ckpt[\"g_ema\"])\n",
    "\n",
    "    g_optim.load_state_dict(ckpt[\"g_optim\"])\n",
    "    d_optim.load_state_dict(ckpt[\"d_optim\"])\n",
    "\n",
    "if args.distributed:\n",
    "    generator = nn.parallel.DistributedDataParallel(\n",
    "        generator,\n",
    "        device_ids=[args.local_rank],\n",
    "        output_device=args.local_rank,\n",
    "        broadcast_buffers=False,\n",
    "    )\n",
    "\n",
    "    discriminator = nn.parallel.DistributedDataParallel(\n",
    "        discriminator,\n",
    "        device_ids=[args.local_rank],\n",
    "        output_device=args.local_rank,\n",
    "        broadcast_buffers=False,\n",
    "    )\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((args.size, args.size)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True),\n",
    "    ]\n",
    ")\n",
    "dataset = CelebAHQ(\"data\", split=\"train\", transform=transform)\n",
    "\n",
    "\n",
    "if get_rank() == 0:\n",
    "    print(f\"dataset: {args.dataset}, size: {args.size}\")\n",
    "\n",
    "loader = data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=args.batch,\n",
    "    sampler=data_sampler(dataset, shuffle=True, distributed=args.distributed),\n",
    "    drop_last=True,\n",
    "    num_workers=args.num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fHL7eCO9sxTa"
   },
   "outputs": [],
   "source": [
    "train(args, loader, generator, discriminator, g_optim, d_optim, g_ema, args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP4fPjCmXQNIcqiVslg1/RH",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch-cuda",
   "language": "python",
   "name": "torch-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
